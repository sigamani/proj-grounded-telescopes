version: "3.9"

services:
  ray-head:
    image: proj-grounded-telescopes:local
    container_name: ray-head
    command: >
      ray start --head
        --dashboard-host=0.0.0.0
        --port=6379
        --dashboard-port=8265
        --block
    ports:
      - "6379:6379"    # Ray client (optional)
      - "8265:8265"    # Ray Dashboard + Jobs REST API
      - "10001:10001"  # Ray client/worker RPC
    volumes:
      - ./:/app
      - ray-data:/tmp/ray           # spill/session
    environment:
      - RAY_ADDRESS=auto
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]  # enable GPUs in Compose
    ipc: host
    ulimits:
      memlock: -1
      stack: 67108864
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8265 || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 10
    networks:
      - ray-network

  # Optional: a thin runner you can `docker compose run --rm jobs-runner ...`
  jobs-runner:
    image: proj-grounded-telescopes:local
    depends_on:
      ray-head:
        condition: service_healthy
    environment:
      - RAY_ADDRESS=ray://ray-head:10001
    working_dir: /app
    entrypoint: ["bash","-lc"]
    command: >
      "python src/batch_infer.py"   # updated path
    volumes:
      - ./:/app
    networks:
      - ray-network

  # Monitoring stack
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"    # Prometheus Web UI
    volumes:
      - ./monitoring/prometheus/prometheus.yaml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.external-url=http://localhost:9090'
    networks:
      - ray-network
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:9090/-/healthy || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"    # Grafana Web UI
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_SERVER_ROOT_URL=http://localhost:3000
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - grafana-data:/var/lib/grafana
    networks:
      - ray-network
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      prometheus:
        condition: service_healthy

  loki:
    image: grafana/loki:latest
    container_name: loki
    ports:
      - "3100:3100"    # Loki API
    volumes:
      - ./monitoring/loki/config.yaml:/etc/loki/local-config.yaml
      - loki-data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - ray-network
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:3100/ready || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  promtail:
    image: grafana/promtail:latest
    container_name: promtail
    volumes:
      - /var/log:/var/log:ro
      - ./monitoring/promtail/config.yaml:/etc/promtail/config.yml
      - ray-data:/tmp/ray:ro          # Mount Ray logs
    command: -config.file=/etc/promtail/config.yml
    networks:
      - ray-network
    depends_on:
      loki:
        condition: service_healthy

networks:
  ray-network:
    driver: bridge

volumes:
  ray-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  loki-data:
    driver: local