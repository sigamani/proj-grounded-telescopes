version: "3.9"

services:
  ray-head:
    image: michaelsigamani/proj-grounded-telescopes:0.1.1
    container_name: ray-head
    command: >
      ray start --head
        --dashboard-host=0.0.0.0
        --port=6379
        --dashboard-port=8265
        --block
    ports:
      - "6379:6379"    # Ray client (optional)
      - "8265:8265"    # Ray Dashboard + Jobs REST API
      - "10001:10001"  # Ray client/worker RPC
    volumes:
      - ./:/app
      - ray-data:/tmp/ray           # spill/session
    environment:
      - RAY_ADDRESS=auto
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]  # enable GPUs in Compose
    ipc: host
    ulimits:
      memlock: -1
      stack: 67108864
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8265 || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 10

  # Optional: a thin runner you can `docker compose run --rm jobs-runner ...`
  jobs-runner:
    image: michaelsigamani/proj-grounded-telescopes:0.1.1
    depends_on:
      ray-head:
        condition: service_healthy
    environment:
      - RAY_ADDRESS=ray://ray-head:10001
    working_dir: /app
    entrypoint: ["bash","-lc"]
    command: >
      "python submit_job.py"   # e.g., client that calls Jobs API; replace as needed
    volumes:
      - ./:/app

volumes:
  ray-data:
    driver: local